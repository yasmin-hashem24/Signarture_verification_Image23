{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\basse\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "from commonfunctions import  *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2gray(image: np.ndarray) -> np.ndarray:\n",
    "    if len(image.shape) > 3:\n",
    "        image = image[:, :, 0:3, 0]\n",
    "    if len(image.shape) == 2:\n",
    "        return image\n",
    "    else:\n",
    "        gray_img = rgb2gray(image)\n",
    "        return gray_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noiseRemoval(img: np.ndarray) -> np.ndarray:\n",
    "    #clean_img = median(img, selem=disk(3))\n",
    "    clean_img = gaussian(img, 1.2)\n",
    "    return clean_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_filter(img,w=10,h=10):\n",
    "    edgex = int(w/2)\n",
    "    edgey = int(h/2)\n",
    "    new_img = np.zeros(img.shape)\n",
    "    for i in range(edgex,img.shape[0]-edgex):\n",
    "        for j in range(edgey,img.shape[1]-edgey):\n",
    "            new_img[i][j] = np.median(img[i-edgex:i+edgex+1,j-edgey:j+edgey+1])\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastEnhancemet(img: np.ndarray) -> None:\n",
    "        enhanced = img.copy()\n",
    "        low, high = np.percentile(img, [0.2, 99.8])\n",
    "        enhanced = rescale_intensity(img, in_range=(low, high))\n",
    "        return enhanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_thresholding_segment(image: np.ndarray, block_size: int, offset: float) -> None:\n",
    "    image = image * 255\n",
    "    binary_image = np.zeros(image.shape, dtype=bool)\n",
    "\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            start_row = max(0, i - block_size // 2)\n",
    "            end_row = min(image.shape[0], i + block_size // 2 + 1)\n",
    "            start_col = max(0, j - block_size // 2)\n",
    "            end_col = min(image.shape[1], j + block_size // 2 + 1)\n",
    "\n",
    "            local_mean = np.mean(image[start_row:end_row, start_col:end_col])\n",
    "\n",
    "            local_threshold = local_mean - offset\n",
    "\n",
    "            binary_image[i, j] = image[i, j] < local_threshold\n",
    "\n",
    "    return binary_image\n",
    "\n",
    "\n",
    "def local_thresholding(image: np.ndarray, block_size: int, offset: float, sections_list: list[np.ndarray], index) -> None:\n",
    "    segmented_image = local_thresholding_segment(image, block_size, offset)\n",
    "    \n",
    "    sections_list[index] = segmented_image\n",
    "\n",
    "def local_thresholding_parallelized(image: np.ndarray, block_size: int, offset: float) -> None:\n",
    "    r, c = image.shape\n",
    "    image_sections = [image[0:r//2, 0:c//2],  image[0:r//2, c//2:c], image[r//2:r, 0:c//2], image[r//2:r, c//2:c]]\n",
    "    \n",
    "    threads = list()\n",
    "    sections_list = [0] * len(image_sections) \n",
    "    for i in range(len(image_sections)):\n",
    "        thread = threading.Thread(target=local_thresholding, args=(image_sections[i], block_size, offset, sections_list, i, ))\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "    \n",
    "    \n",
    "    image[0:r//2, 0:c//2] = sections_list[0]\n",
    "    image[0:r//2, c//2:c] = sections_list[1]\n",
    "    image[r//2:r, 0:c//2] = sections_list[2]\n",
    "    image[r//2:r, c//2:c] = sections_list[3]\n",
    "    return image\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def local_thresholding(image, block_size, offset):\n",
    "\n",
    "#     # Initialize an array to store the binary image\n",
    "#     binary_image = np.zeros(image.shape, dtype=bool)\n",
    "\n",
    "#     # Iterate over the image pixels\n",
    "#     for i in range(image.shape[0]):\n",
    "#         for j in range(image.shape[1]):\n",
    "#             # Define the pixel neighborhood\n",
    "#             start_row = max(0, i - block_size // 2)\n",
    "#             end_row = min(image.shape[0], i + block_size // 2 + 1)\n",
    "#             start_col = max(0, j - block_size // 2)\n",
    "#             end_col = min(image.shape[1], j + block_size // 2 + 1)\n",
    "\n",
    "#             # Compute the local mean of the neighborhood\n",
    "#             local_mean = np.mean(image[start_row:end_row, start_col:end_col])\n",
    "\n",
    "#             # Compute the local threshold\n",
    "#             local_threshold = local_mean - offset\n",
    "\n",
    "#             # Set the pixel value in the binary image based on the local threshold\n",
    "#             binary_image[i, j] = image[i, j] < local_threshold\n",
    "\n",
    "#     return binary_image\n",
    "\n",
    "def binarize(img: np.ndarray) -> None:\n",
    "    block_size = 25\n",
    "    binarized_img = local_thresholding_parallelized(img, block_size, 10)\n",
    "    return binarized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skewCorrection(img: np.ndarray) -> np.ndarray:\n",
    "    skew_corrected_imgs = transform.resize(img, (128, 256), mode='reflect', anti_aliasing=True)\n",
    "    return skew_corrected_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img: np.ndarray) -> np.ndarray:\n",
    "    gray_img = img2gray(img)\n",
    "    clean_img = noiseRemoval(gray_img)\n",
    "    enhanced_img = contrastEnhancemet(clean_img)\n",
    "    binarized_img = binarize(enhanced_img)\n",
    "   # show_images([binarized_img])\n",
    "    skew_corrected_img = skewCorrection(opening(binarized_img,rectangle(5,5)))\n",
    "    skeletonized_img = skeletonize(skew_corrected_img)\n",
    "    return skeletonized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readDataset(dir: str) -> list[np.ndarray]:\n",
    "    dataset = []\n",
    "    read_imgs = os.listdir(dir)\n",
    "    for i in range(len(read_imgs)):\n",
    "        image = io.imread(dir + read_imgs[i]).astype(np.uint8)\n",
    "        dataset.append(preprocess(image))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HOGFeatureExtractionSkimage(image: np.ndarray) -> np.ndarray:\n",
    "    image = image.astype(np.uint8)\n",
    "    features = hog(image, orientations=9, pixels_per_cell=(9, 9),\n",
    "    cells_per_block=(3,3), transform_sqrt=True, block_norm=\"L1\")\n",
    "    return features\n",
    "\n",
    "def extractFeatures(imgs: list[np.ndarray]) -> list[np.ndarray]:\n",
    "    extracted_features = []\n",
    "    for i in range(len(imgs)):\n",
    "        extracted_features.append(HOGFeatureExtractionSkimage(imgs[i]))\n",
    "    return extracted_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_imgs = readDataset('all/real/')\n",
    "forged_imgs = readDataset('all/forged/')\n",
    "test_imgs = readDataset('testImgs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_extracted_features = extractFeatures(real_imgs)\n",
    "forged_extracted_features = extractFeatures(forged_imgs)\n",
    "test_extraced_features = extractFeatures(test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOG_features = forged_extracted_features + real_extracted_features\n",
    "HOG_labels_forged = [0 for _ in range(len(forged_extracted_features))]\n",
    "HOG_labels_real = [1 for _ in range(len(real_extracted_features))]\n",
    "HOG_labels = HOG_labels_forged + HOG_labels_real\n",
    "test_imgs_label = 1\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(HOG_features, HOG_labels, test_size = 0.2, random_state = 42)\n",
    "model = svm.SVC(kernel='linear')\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "accuracy = model.score(x_test, y_test)\n",
    "print(\"SVM using HOG as feature descriptor.\", 'accuracy:', accuracy * 100, '%')\n",
    "accuracy = model.score(x_train, y_train)\n",
    "print(\"SVM using HOG as feature descriptor.\", 'accuracy:', accuracy * 100, '%')\n",
    "\n",
    "dump(model, 'model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_prediction = model.predict(test_extraced_features)\n",
    "print(test_prediction)\n",
    "if test_prediction == test_imgs_label:\n",
    "    print(\"correct prediction\")\n",
    "else:\n",
    "    print(\"false prediction\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
